{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 14)\n",
    "\n",
    "def plot2d(image, title=\"\", max=None, min=0, cmap=\"gray\", switch_channels=True):\n",
    "    plt.title(title)\n",
    "    if not switch_channels or image.ndim == 2:\n",
    "        if max == None:\n",
    "            plt.imshow(image, cmap=cmap, interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(image, cmap=cmap, interpolation=\"none\", vmin = min, vmax = max)\n",
    "    else:\n",
    "        if max == None:\n",
    "            plt.imshow(image[:,:,::-1], cmap=cmap, interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(image[:,:,::-1], cmap=cmap, interpolation=\"none\", vmin = min, vmax = max)\n",
    "    plt.show()\n",
    "\n",
    "def show(image, title=\"\", bw=True):\n",
    "    if bw:\n",
    "        plt.imshow(image,cmap=\"Greys_r\", vmin=0, vmax=255)\n",
    "    else:\n",
    "        plt.imshow(image.astype(np.uint8), vmin=0, vmax=255)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stitch_images(images, match_threshold = 750, ransac_threshold = 5, verbose=False):\n",
    "#     images = map(lambda img: cv2.resize(img, (600,600)), images)\n",
    "    images_orig = images\n",
    "    images = list(map(lambda img: cv2.cvtColor(img, cv2.COLOR_BGR2GRAY), images))\n",
    "    feature_sets = find_features(images_orig, images, verbose)\n",
    "    matches = match_feature_sets(feature_sets, match_threshold, verbose)\n",
    "    homographies = ransac_images(matches, feature_sets, ransac_threshold, False)\n",
    "    warped_images= warp_images(homographies, images_orig)\n",
    "    stitched_image = composite_images(warped_images)\n",
    "    return stitched_image\n",
    "    \n",
    "    \n",
    "        \n",
    "def draw_sidebyside(im1, im2):\n",
    "    h1,w1 = im1.shape\n",
    "    h2,w2 = im2.shape\n",
    "    out = np.zeros((h1, w1+w2, 3), dtype=float)\n",
    "    out[:,:w1,0] = im1\n",
    "    out[:,:w1,1] = im1\n",
    "    out[:,:w1,2] = im1\n",
    "    out[:,w1:,0] = im2\n",
    "    out[:,w1:,1] = im2\n",
    "    out[:,w1:,2] = im2\n",
    "    return out, w1,w2\n",
    "    \n",
    "    \n",
    "def draw_samples(random_sample, set1, set2, image1, image2):\n",
    "    out,w1,w2 = draw_sidebyside(image1,image2)\n",
    "    \n",
    "    for s in random_sample:\n",
    "        s1 = set1[1][s.queryIdx].pt\n",
    "        s2 = set2[1][s.trainIdx].pt\n",
    "        cv2.circle(out, (int(s1[0]), int(s1[1])), 8, (255,255,255), 4)\n",
    "        cv2.circle(out, (int(w1 + s2[0]), int(s2[1])), 8, (255,255,255), 4)\n",
    "    return out\n",
    "\n",
    "def ransac_image(matches, set1, set2, threshold, verbose=False):\n",
    "    n = len(matches) # Number of data points\n",
    "    m = 4 # Minimum needed for homography\n",
    "    p = 0.5 # Portion of n points that we believe to be inliers (underestimate)\n",
    "    confidence = 0.99 # Confidence that we've picked the correct solution\n",
    "    #confidence = 1 - (1 - p ** m) ** k # Number of RANSAC interations needed\n",
    "    k = math.log(1 - confidence, (1 - p ** m)) # Solve for k to find number of iterations to achieve desired confidence\n",
    "    k = int(math.ceil(k))\n",
    "    \n",
    "    consensus_sets = []\n",
    "    for i in range(k):\n",
    "        random_sample = []\n",
    "        for j in range(m):\n",
    "            random_sample.append(random.choice(matches))\n",
    "        \n",
    "        if verbose:\n",
    "            out = draw_samples(random_sample, set1, set2, set1[0], set2[0])\n",
    "            plot2d(out)\n",
    "            \n",
    "        homography, cs_size = calculate_consensus_set_size(random_sample, matches, set1, set2, threshold, verbose)\n",
    "        cs_item = (random_sample, homography, cs_size)\n",
    "        consensus_sets.append(cs_item)\n",
    "    \n",
    "    largest_consensus_set = max(consensus_sets, key=lambda s: s[2])\n",
    "    return largest_consensus_set[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "def ransac_images(matches_lists, feature_sets, threshold, verbose=False):\n",
    "    homographies = []\n",
    "    for i in range(len(matches_lists)):\n",
    "        matches = matches_lists[i]\n",
    "        set1 = feature_sets[i]\n",
    "        set2 = feature_sets[i + 1]\n",
    "        homography = ransac_image(matches, set1, set2,\n",
    "                                  threshold,\n",
    "                                  verbose)\n",
    "        homographies.append(homography)\n",
    "    return homographies\n",
    "        \n",
    "        \n",
    "    \n",
    "def find_features(images_orig, images, verbose=False):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    feature_sets = []\n",
    "    for i in range(len(list(images))):\n",
    "        keypoints, descriptors = sift.detectAndCompute(images[i], None)\n",
    "        if verbose:\n",
    "            im = cv2.drawKeypoints(images[i], keypoints,images[i], flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "            plot2d(im)\n",
    "        feature_set = (images[i],keypoints, descriptors, images_orig[i])\n",
    "        feature_sets.append(feature_set)\n",
    "    return feature_sets\n",
    "\n",
    "\n",
    "def find_putative_matches(set1, set2, threshold, verbose=False):\n",
    "    bf_matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck=True)\n",
    "    putative_matches = bf_matcher.match(set1[2], set2[2])\n",
    "    thresholded = [x for x in putative_matches if x.distance < threshold]\n",
    "    if verbose:\n",
    "        out_img = None\n",
    "        out_img = cv2.drawMatches(set1[0], set1[1], set2[0], set2[1], thresholded, out_img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        plot2d(out_img)\n",
    "    return thresholded\n",
    "    \n",
    "        \n",
    "def match_feature_sets(feature_sets, threshold, verbose):\n",
    "    putative_matches_lists = []\n",
    "    for i in range(1, len(feature_sets)):\n",
    "#     for i in range(1, len(feature_sets) + 1):\n",
    "        feature_set1 = feature_sets[i - 1]\n",
    "        feature_set2 = feature_sets[i]\n",
    "#         feature_set2 = feature_sets[i % len(feature_sets)]\n",
    "        putative_matches = find_putative_matches(feature_set1, feature_set2, threshold, verbose)\n",
    "        putative_matches_lists.append(putative_matches)\n",
    "    return putative_matches_lists\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Homography stuff\n",
    "def estimate_homography(s1, s2):\n",
    "    x1 = s1[0].pt[0]\n",
    "    y1 = s1[0].pt[1]\n",
    "    X1 = s2[0].pt[0]\n",
    "    Y1 = s2[0].pt[1]\n",
    "    \n",
    "    x2 = s1[1].pt[0]\n",
    "    y2 = s1[1].pt[1]\n",
    "    X2 = s2[1].pt[0]\n",
    "    Y2 = s2[1].pt[1]\n",
    "    \n",
    "    x3 = s1[2].pt[0]\n",
    "    y3 = s1[2].pt[1]\n",
    "    X3 = s2[2].pt[0]\n",
    "    Y3 = s2[2].pt[1]\n",
    "    \n",
    "    x4 = s1[3].pt[0]\n",
    "    y4 = s1[3].pt[1]\n",
    "    X4 = s2[3].pt[0]\n",
    "    Y4 = s2[3].pt[1]\n",
    "    \n",
    "    A = np.array(\n",
    "    [[x1, y1, 1,  0,  0, 0, -X1 * x1, -X1 * y1],\n",
    "     [ 0,  0, 0, x1, y1, 1, -Y1 * x1, -Y1 * y1],\n",
    "     [x2, y2, 1,  0,  0, 0, -X2 * x2, -X2 * y2],\n",
    "     [ 0,  0, 0, x2, y2, 1, -Y2 * x2, -Y2 * y2],\n",
    "     [x3, y3, 1,  0,  0, 0, -X3 * x3, -X3 * y3],\n",
    "     [ 0,  0, 0, x3, y3, 1, -Y3 * x3, -Y3 * y3],\n",
    "     [x4, y4, 1,  0,  0, 0, -X4 * x4, -X4 * y4],\n",
    "     [ 0,  0, 0, x4, y4, 1, -Y4 * x4, -Y4 * y4]],\n",
    "        dtype=float)\n",
    "    b = np.array(\n",
    "    [[X1],\n",
    "     [Y1],\n",
    "     [X2],\n",
    "     [Y2],\n",
    "     [X3],\n",
    "     [Y3],\n",
    "     [X4],\n",
    "     [Y4]],\n",
    "        dtype=float)\n",
    "    \n",
    "    if np.linalg.det(A) != 0:\n",
    "        x = np.linalg.solve(A, b)\n",
    "        x = np.array(\n",
    "        [[x[0], x[1], x[2]],\n",
    "         [x[3], x[4], x[5]],\n",
    "         [x[6], x[7],   1]], dtype=float)\n",
    "        return x\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def project_match(homography, match, set1):\n",
    "    p1 = set1[1][match.queryIdx].pt\n",
    "    h = homography\n",
    "    \n",
    "    x = p1[0]\n",
    "    y = p1[1]\n",
    "    \n",
    "    X = (h[0,0] * x + h[0,1] * y + h[0,2]) / (h[2,0] * x + h[2,1] * y + 1.0)\n",
    "    Y = (h[1,0] * x + h[1,1] * y + h[1,2]) / (h[2,0] * x + h[2,1] * y + 1.0)\n",
    "    \n",
    "    P_est = np.array(\n",
    "    [[X],\n",
    "     [Y]], dtype=float)\n",
    "    return P_est\n",
    "    \n",
    "    \n",
    "def draw_projected(Ps, image1, image2):\n",
    "    out,w1,w2 = draw_sidebyside(image1,image2)\n",
    "    for p in Ps:\n",
    "        orig = p[0]\n",
    "        actual = p[1]\n",
    "        est = p[2]\n",
    "        cv2.circle(out, (orig[0], orig[1]), 8, (0,255,0), 2)\n",
    "        cv2.line(out, (w1+actual[0], actual[1]), (w1+est[0], est[1]), (0,0,255), 4)\n",
    "        cv2.circle(out, (w1+actual[0], actual[1]), 8, (0,255,0), 2)\n",
    "        cv2.circle(out, (w1+est[0], est[1]), 8, (255,0,0), 2)\n",
    "    return out\n",
    "\n",
    "def calculate_consensus_set_size(random_sample, matches, set1, set2, threshold, verbose=False):\n",
    "    sample_set1 = list(map(lambda p: set1[1][p.queryIdx], random_sample))\n",
    "    sample_set2 = list(map(lambda p: set2[1][p.trainIdx], random_sample))\n",
    "    homography = estimate_homography(sample_set1, sample_set2)\n",
    "    if homography is None:\n",
    "#         print \"Singular Matrix!\"\n",
    "        return None, 0\n",
    "    cs_size = 0\n",
    "    \n",
    "    if verbose:\n",
    "        Ps = []\n",
    "        Ps_close = []\n",
    "    for match in matches:\n",
    "        p1 = set1[1][match.queryIdx].pt\n",
    "        P_orig = np.array(\n",
    "        [[p1[0]],\n",
    "         [p1[1]]], dtype=float)\n",
    "        p2 = set2[1][match.trainIdx].pt\n",
    "        P_actual = np.array(\n",
    "        [[p2[0]], \n",
    "         [p2[1]]], dtype=float)\n",
    "        P_est = project_match(homography, match, set1)\n",
    "        \n",
    "        error = np.linalg.norm(P_actual - P_est)\n",
    "        if error < threshold:\n",
    "            cs_size += 1\n",
    "            if verbose:\n",
    "                Ps_close.append((P_orig, P_actual, P_est))\n",
    "        if verbose:\n",
    "#             print error\n",
    "            Ps.append((P_orig, P_actual, P_est))\n",
    "    \n",
    "    if verbose:\n",
    "        out = draw_projected(Ps_close[::], set1[0], set2[0])\n",
    "        plot2d(out, switch_channels=True)\n",
    "        cv2.imwrite(\"projected.png\", out)\n",
    "    \n",
    "    return (homography, cs_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def combine_homographies(homographies):\n",
    "    M = homographies[0]\n",
    "    M /= M[2,2]\n",
    "    h = [M]\n",
    "    for i in range(len(homographies)):\n",
    "        M = np.matmul( M, np.linalg.inv(homographies[i]))\n",
    "        M /= M[2,2]\n",
    "        h.append(M)\n",
    "    return h\n",
    "        \n",
    "def find_extents(homographies, image_sizes):\n",
    "    minX = 0\n",
    "    minY = 0\n",
    "    maxX = 0\n",
    "    maxY = 0\n",
    "    for i in range(len(homographies)):\n",
    "        im = image_sizes[i]\n",
    "        tl = np.array([[0],[0],[1]], dtype=float)\n",
    "        tr = np.array([[im[1]],[0],[1]], dtype=float)\n",
    "        bl = np.array([[0],[im[0]],[1]], dtype=float)\n",
    "        br = np.array([[im[1]],[im[0]],[1]], dtype=float)\n",
    "\n",
    "        tl = np.matmul(homographies[i], tl)\n",
    "        tr = np.matmul(homographies[i], tr)\n",
    "        bl = np.matmul(homographies[i], bl)\n",
    "        br = np.matmul(homographies[i], br)\n",
    "\n",
    "        tl /= tl[2]\n",
    "        tr /= tr[2]\n",
    "        bl /= bl[2]\n",
    "        br /= br[2]\n",
    "\n",
    "        minX = min(minX, tl[0,0], bl[0,0], tr[0,0], br[0,0])\n",
    "        minY = min(minY, tl[1,0], bl[1,0], tr[1,0], br[1,0])\n",
    "        maxX = max(maxX, tl[0,0], bl[0,0], tr[0,0], br[0,0])\n",
    "        maxY = max(maxY, tl[1,0], bl[1,0], tr[1,0], br[1,0])\n",
    "        \n",
    "    return minX, minY, maxX, maxY\n",
    "        \n",
    "    \n",
    "        \n",
    "def shift_homographies(homographies, minX, minY):\n",
    "    out = []\n",
    "    for h in homographies:\n",
    "        shift = np.array(\n",
    "        [[1, 0, -minX],\n",
    "         [0, 1, -minY],\n",
    "         [0, 0,     1]], dtype=float)\n",
    "        m = np.matmul(shift, h)\n",
    "        m /= m[2,2]\n",
    "        out.append(m)\n",
    "    return out\n",
    "\n",
    "def warp_images(homographies, images, verbose=False):\n",
    "    homographies = combine_homographies(homographies)\n",
    "    minX, minY, maxX, maxY = find_extents(homographies, list(map(lambda i: i.shape, images)))\n",
    "    homographies = shift_homographies(homographies, minX,minY)\n",
    "    w = int(math.ceil(maxX - minX))\n",
    "    h = int(math.ceil(maxY - minY))\n",
    "    \n",
    "    warped_images = []\n",
    "    for i in range(len(images)):\n",
    "        M = homographies[i]\n",
    "        warped = cv2.warpPerspective(images[i], M, (w, h))\n",
    "        white = np.ones((images[i].shape[0], images[i].shape[1], 3), dtype=float)\n",
    "        mask = cv2.warpPerspective(white, M, (w,h))\n",
    "        warped_images.append((warped,mask))\n",
    "        if verbose:\n",
    "            plot2d(warped)\n",
    "            cv2.imwrite(str(i) + \".png\", warped)\n",
    "    return warped_images\n",
    "\n",
    "def find_mask_extents(mask):\n",
    "    minX = mask.shape[1]\n",
    "    maxX = 0\n",
    "    for i in range(mask.shape[0]):\n",
    "        indices = np.where(mask[i] > 0)\n",
    "        if indices[0].shape[0] > 0:\n",
    "            first_index = indices[0][0]\n",
    "            last_index = indices[0][-1]\n",
    "        else:\n",
    "            first_index = minX\n",
    "            last_index = maxX\n",
    "        if first_index < minX:\n",
    "            minX = first_index\n",
    "        if last_index > maxX:\n",
    "            maxX = last_index\n",
    "    return minX,maxX\n",
    "        \n",
    "    \n",
    "def make_gradient(img_w, img_h, minX, maxX):\n",
    "    width = maxX - minX\n",
    "    u = np.linspace(start=0, stop=1, num=width, endpoint=True, dtype='float64')\n",
    "    t = np.linspace(start=0, stop=1, num=img_h, endpoint=True, dtype='float64')\n",
    "    x,y = np.meshgrid(u, t)\n",
    "    \n",
    "    gradient = np.zeros((img_h,img_w, 3), dtype=float)\n",
    "    gradient[:,minX:maxX, 0] = x\n",
    "    gradient[:,minX:maxX, 1] = x\n",
    "    gradient[:,minX:maxX, 2] = x\n",
    "    return gradient\n",
    "\n",
    "def blend_mask(mask, prev_mask):\n",
    "    intersect = np.logical_and(mask, prev_mask)\n",
    "    minX,maxX = find_mask_extents(intersect)\n",
    "    gradient = make_gradient(mask.shape[1], mask.shape[0], minX, maxX + 1)\n",
    "    out = gradient * intersect\n",
    "    subtraction = mask - intersect\n",
    "    out = out + subtraction\n",
    "    return out\n",
    "    \n",
    "def composite_images(warped_images):\n",
    "    out = np.zeros((warped_images[0][0].shape), dtype=float)\n",
    "    for i in range(len(warped_images)):\n",
    "        img, mask = warped_images[i]\n",
    "        prev_img, prev_mask = warped_images[i-1]\n",
    "        if i > 0:\n",
    "            mask = blend_mask(mask, prev_mask)\n",
    "        out = (img * mask) + (out * (1 - mask))\n",
    "        out[out < 0] = 0\n",
    "        out[out > 255] = 255\n",
    "    return out\n",
    "\n",
    "\n",
    "im1 = cv2.imread(\"i1.jpg\")\n",
    "im2 = cv2.imread(\"i2.jpg\")\n",
    "#im3 = cv2.imread(\"img3.jpg\")\n",
    "images = [im1, im2]#, im3]\n",
    "stitched = stitch_images(images, verbose=True)\n",
    "cv2.imwrite(\"stitched.png\", stitched)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
